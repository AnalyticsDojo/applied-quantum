{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "\n# \ud83e\udde9 Product Recommendation Systems \u2014 MF (ALS) + Quantum-Inspired QUBO (Colab-Ready)\n\nThis notebook demonstrates a hybrid **classical\u2013quantum approach** to product recommendations on a **synthetic dataset**:\n\n1. **Classical Matrix Factorization (ALS)**  \n   - Implicit feedback (click/purchase) dataset  \n   - Alternating Least Squares (ALS) with L2 regularization  \n   - Evaluation: **HitRate@K** and **NDCG@K**\n\n2. **Quantum-Inspired Boltzmann / Ising QUBO**  \n   - Learn **item\u2013item couplings** from co-occurrence (PMI-like).  \n   - Combine **MF scores** (linear fields) and couplings with a **Top-N constraint**.  \n   - Solve with `neal` (simulated annealing).\n\nBoth use the same dataset for fair comparison.\n"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "\n# Install dependencies (dimod + neal) if missing\ndef _silent_imports():\n    flags = {\"dimod\": False, \"neal\": False}\n    try:\n        import dimod\n        flags[\"dimod\"] = True\n    except Exception:\n        pass\n    try:\n        import neal\n        flags[\"neal\"] = True\n    except Exception:\n        pass\n    return flags\n\nflags = _silent_imports()\nif not flags[\"dimod\"] or not flags[\"neal\"]:\n    %pip -q install dimod neal\n\nflags = _silent_imports()\nprint(\"dimod:\", flags[\"dimod\"], \"| neal:\", flags[\"neal\"])\n"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "\n# ==== Synthetic User\u2013Item Interaction Dataset ====\nimport numpy as np, pandas as pd\n\nrng = np.random.default_rng(2028)\n\nU = 400     # users\nI = 250     # items\nK = 10      # latent factors\ndensity = 0.05\n\n# Latent factors (true)\nU_true = rng.normal(0, 1, (U, K))\nV_true = rng.normal(0, 1, (I, K))\nbias_item = rng.normal(0, 0.3, size=I)\n\n# Generate implicit feedback (Bernoulli with sigmoid)\ndef sigmoid(x): return 1 / (1 + np.exp(-x))\nscore = U_true @ V_true.T + bias_item[None, :]\nprob = sigmoid(score)\nmask = rng.random((U, I)) < density\nY = (rng.random((U, I)) < prob) & mask\nY = Y.astype(int)\n\n# Leave-one-out test\ntrain = Y.copy()\ntest_pos = -np.ones(U, dtype=int)\nfor u in range(U):\n    pos = np.where(Y[u] == 1)[0]\n    if len(pos) > 0:\n        hold = rng.choice(pos)\n        train[u, hold] = 0\n        test_pos[u] = hold\n\nprint(f\"Users={U}, Items={I}, Positives={Y.sum()}\")\n"}, {"cell_type": "markdown", "metadata": {}, "source": "\n## Part 1 \u2014 Matrix Factorization (ALS)\n"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "\n# ALS implementation (no external dependencies)\nimport numpy as np\n\ndef als_implicit(train, K=10, reg=0.1, iters=10, seed=0):\n    rng = np.random.default_rng(seed)\n    U, I = train.shape\n    P = rng.normal(0, 0.1, (U, K))\n    Q = rng.normal(0, 0.1, (I, K))\n    I_K = reg * np.eye(K)\n    for _ in range(iters):\n        # Update P\n        QTQ = Q.T @ Q + I_K\n        for u in range(U):\n            idx = np.where(train[u] == 1)[0]\n            if len(idx) == 0: continue\n            Q_u = Q[idx]\n            A = QTQ + Q_u.T @ Q_u - I_K\n            b = Q_u.T @ np.ones(len(idx))\n            P[u] = np.linalg.solve(A, b)\n        # Update Q\n        PTP = P.T @ P + I_K\n        for i in range(I):\n            idx = np.where(train[:, i] == 1)[0]\n            if len(idx) == 0: continue\n            P_i = P[idx]\n            A = PTP + P_i.T @ P_i - I_K\n            b = P_i.T @ np.ones(len(idx))\n            Q[i] = np.linalg.solve(A, b)\n    return P, Q\n\nP, Q = als_implicit(train, K=K, reg=0.2, iters=12)\nS_mf = P @ Q.T\nprint(\"MF mean/std scores:\", round(S_mf.mean(), 4), round(S_mf.std(), 4))\n"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "\n# Evaluate HitRate@K and NDCG@K\ndef evaluate_topk(S, train, test_pos, Krec=10, n_negs=100, seed=0):\n    rng = np.random.default_rng(seed)\n    U, I = S.shape\n    hits = ndcg = 0\n    valid_users = 0\n    for u in range(U):\n        tp = test_pos[u]\n        if tp < 0: continue\n        negs = np.setdiff1d(np.arange(I), np.concatenate([[tp], np.where(train[u]==1)[0]]))\n        if len(negs) < n_negs: continue\n        neg_sample = rng.choice(negs, n_negs, replace=False)\n        cand = np.concatenate([[tp], neg_sample])\n        scores = S[u, cand]\n        order = np.argsort(-scores)\n        rank = np.where(order == 0)[0][0]\n        if rank < Krec:\n            hits += 1\n            ndcg += 1 / np.log2(rank + 2)\n        valid_users += 1\n    return hits / valid_users, ndcg / valid_users\n\nhit10, ndcg10 = evaluate_topk(S_mf, train, test_pos)\nprint(\"MF HitRate@10:\", round(hit10, 4), \"| NDCG@10:\", round(ndcg10, 4))\n"}, {"cell_type": "markdown", "metadata": {}, "source": "\n## Part 2 \u2014 Quantum-Inspired QUBO Recommendation\n"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "\nfrom collections import defaultdict\nimport dimod, neal\n\n# Compute co-occurrence matrix for PMI-like coupling\nitem_pop = train.mean(axis=0)\npair_pop = (train.T @ train) / train.shape[0]\nP_i = item_pop\nP_ij = pair_pop / pair_pop.max()\nnp.fill_diagonal(P_ij, P_i)\n\nPMI = np.log((P_ij + 1e-9) / (P_i[:, None] * P_i[None, :] + 1e-9))\nPMI = np.maximum(0.0, PMI)\nnp.fill_diagonal(PMI, 0.0)\nh_item = np.log((P_i + 1e-6) / (1 - P_i + 1e-6))\n\ndef qubo_recommend(u, S_mf, Nrec=10, M_cand=80, alpha=1.0, beta=0.2, gamma=0.6, A=6.0, seed=0):\n    rng = np.random.default_rng(seed)\n    seen = np.where(train[u] == 1)[0]\n    unseen = np.setdiff1d(np.arange(I), seen)\n    if len(unseen) == 0: return []\n    scores = S_mf[u, unseen]\n    top_idx = np.argsort(-scores)[:min(M_cand, len(unseen))]\n    cand = unseen[top_idx]\n    m = len(cand)\n\n    Q = defaultdict(float)\n    for a, i in enumerate(cand):\n        Q[(a, a)] += - (alpha * S_mf[u, i] + beta * h_item[i])\n    for a, i in enumerate(cand):\n        for b in range(a + 1, m):\n            j = cand[b]\n            Q[(a, b)] += - gamma * PMI[i, j]\n    for a in range(m):\n        Q[(a, a)] += A * (1 - 2 * Nrec)\n    for a in range(m):\n        for b in range(a + 1, m):\n            Q[(a, b)] += 2 * A\n\n    bqm = dimod.BinaryQuadraticModel.from_qubo(dict(Q))\n    ss = neal.SimulatedAnnealingSampler().sample(bqm, num_reads=800, seed=seed)\n    best = ss.first.sample\n    chosen = [cand[a] for a in range(m) if best.get(a, 0) == 1]\n\n    if len(chosen) < Nrec:\n        pad = [i for i in cand if i not in chosen]\n        pad = pad[:Nrec - len(chosen)]\n        chosen += pad\n    elif len(chosen) > Nrec:\n        chosen = chosen[:Nrec]\n    return chosen\n\n# Example\nexamples = {u: qubo_recommend(u, S_mf, seed=42 + u) for u in range(3)}\nexamples\n"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "\n# Compare QUBO vs MF on test positives\ndef eval_user(u, rec_list, test_pos):\n    tp = test_pos[u]\n    if tp < 0: return 0, 0\n    if tp in rec_list:\n        rank = rec_list.index(tp)\n        return 1, 1 / np.log2(rank + 2)\n    return 0, 0\n\nusers_eval = 200\nhits_mf = ndcg_mf = hits_qb = ndcg_qb = 0\nrng = np.random.default_rng(1)\nusers = rng.choice([u for u in range(U) if test_pos[u] >= 0], size=users_eval, replace=False)\n\nfor u in users:\n    rec_mf = np.argsort(-S_mf[u])\n    rec_mf = [i for i in rec_mf if train[u, i] == 0][:10]\n    rec_qb = qubo_recommend(u, S_mf, seed=u + 10)\n    h, g = eval_user(u, rec_mf, test_pos); hits_mf += h; ndcg_mf += g\n    h, g = eval_user(u, rec_qb, test_pos); hits_qb += h; ndcg_qb += g\n\nprint(\"MF  @10 \u2014 Hit:\", round(hits_mf / users_eval, 4), \"NDCG:\", round(ndcg_mf / users_eval, 4))\nprint(\"QUBO@10 \u2014 Hit:\", round(hits_qb / users_eval, 4), \"NDCG:\", round(ndcg_qb / users_eval, 4))\n"}, {"cell_type": "markdown", "metadata": {}, "source": "\n### Notes\n- **Matrix Factorization** provides linear predictions from latent factors.  \n- The **QUBO** step acts as a **Boltzmann machine**, coupling items via PMI co-occurrence.  \n- You can tune `gamma` for coherence (positive = similar items, negative = diverse).  \n- The QUBO structure can extend to **quantum annealers** or **tensor-network samplers** for large-scale factorization.\n"}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}