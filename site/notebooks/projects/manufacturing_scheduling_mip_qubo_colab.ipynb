{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "\n# Unified Manufacturing Scheduling \u2014 MIP (PuLP) + QUBO (neal) on One Dataset\n\nThis notebook demonstrates **Job Shop Scheduling (JSSP)** on a **single synthetic dataset** using two approaches:\n\n1. **Classical MIP (PuLP)**  \n   - Variables: start times \\(S_{j,k}\\) for each job \\(j\\) operation \\(k\\), sequencing binaries on each machine, and makespan \\(C_{\\max}\\).  \n   - Objective: **minimize makespan** subject to machine non-overlap and job precedence.\n\n2. **QUBO (time-indexed)** with **simulated annealing** (`neal`)  \n   - Variables: binary one-hot \\(x_{(j,k),t}\\) indicates operation \\((j,k)\\) starts at time \\(t\\).  \n   - Penalties enforce: **each operation starts exactly once**, **no machine overlap per time slot**, and **precedence** between consecutive operations within a job.\n\n**Dataset:** We generate one set of \\(J\\) jobs and \\(M\\) machines. Each job requires exactly one operation on **each** machine in a (random) route, with processing times sampled randomly. The same dataset feeds both approaches.\n"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "\n# Install missing deps (works in Colab):\n# - PuLP for MIP\n# - dimod/neal for QUBO simulated annealing\n\ndef _silent_imports():\n    flags = {\"pulp\": False, \"dimod\": False, \"neal\": False}\n    try:\n        import pulp  # noqa: F401\n        flags[\"pulp\"] = True\n    except Exception:\n        pass\n    try:\n        import dimod  # noqa: F401\n        flags[\"dimod\"] = True\n    except Exception:\n        pass\n    try:\n        import neal  # noqa: F401\n        flags[\"neal\"] = True\n    except Exception:\n        pass\n    return flags\n\nflags = _silent_imports()\nif not flags[\"pulp\"]:\n    %pip -q install pulp\nif not flags[\"dimod\"] or not flags[\"neal\"]:\n    %pip -q install dimod neal\n\nflags = _silent_imports()\nprint(\"PuLP:\", flags[\"pulp\"], \"| dimod:\", flags[\"dimod\"], \"| neal:\", flags[\"neal\"])\n"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "\n# ==== One Synthetic Dataset ====\nimport numpy as np, pandas as pd\n\nrng = np.random.default_rng(123)\n\nJ = 5   # jobs\nM = 3   # machines\njobs = [f\"J{j+1}\" for j in range(J)]\nmachines = [f\"M{m+1}\" for m in range(M)]\n\n# Each job has M operations; route is a random permutation of machines\nroutes = {j: list(rng.permutation(machines)) for j in jobs}\n\n# Processing times p[j][op_machine]\nproc_times = {j: {m: int(rng.integers(2, 9)) for m in machines} for j in jobs}\n\n# Upper bound on horizon (sum of max per job)\nH = int(sum(max(proc_times[j][m] for m in machines) for j in jobs) + 5)\n\ndf_routes = pd.DataFrame({j: routes[j] for j in jobs})\ndf_pt = pd.DataFrame(proc_times).T[machines]  # rows jobs, cols machines\n\nprint(\"Jobs:\", jobs)\nprint(\"Machines:\", machines)\nprint(\"Time horizon H:\", H)\ndf_routes, df_pt\n"}, {"cell_type": "markdown", "metadata": {}, "source": "\n## Part 1 \u2014 MIP (Minimize Makespan) with PuLP (Heuristic Fallback)\n\n**MIP model (disjunctive):**\n- \\(S_{j,k}\\): start time of operation \\(k\\) of job \\(j\\) (continuous \\(\\ge 0\\)).  \n- \\(C_{\\max}\\): makespan (continuous).  \n- For each machine \\(m\\), for any two operations \\(a,b\\) processed on \\(m\\), introduce binary \\(y_{a,b}\\) s.t. either \\(a\\) precedes \\(b\\) or vice versa.\n\n**Constraints:**\n- **Precedence** within a job: next operation starts after previous finishes.  \n- **Machine non-overlap**: one operation at a time on each machine.  \n- **Makespan**: operation completion \\(\\le C_{\\max}\\).\n\nIf PuLP is unavailable, we use a **greedy heuristic** (Giffler-Thompson\u2013style) as a fallback.\n"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "\nimport math, pandas as pd, numpy as np\n\ntry:\n    import pulp\n    HAVE_PULP = True\nexcept Exception:\n    HAVE_PULP = False\n\n# Build operation list: for each job j, we define ordered ops as (j, k, machine m_k, proc p)\nops = []  # list of dicts\nop_index = {}\nfor j in jobs:\n    route = routes[j]\n    for k, m in enumerate(route):\n        ops.append({\"job\": j, \"op_idx\": k, \"machine\": m, \"p\": int(proc_times[j][m])})\nop_ids = [f\"{o['job']}_{o['op_idx']}\" for o in ops]\nfor idx, oid in enumerate(op_ids):\n    op_index[oid] = idx\n\ndef solve_mip_jobshop(ops, jobs, machines, H):\n    prob = pulp.LpProblem(\"JSSP_Makespan\", pulp.LpMinimize)\n    # Start time variables and Cmax\n    S = {oid: pulp.LpVariable(f\"S_{oid}\", lowBound=0, cat=\"Continuous\") for oid in op_ids}\n    Cmax = pulp.LpVariable(\"Cmax\", lowBound=0, cat=\"Continuous\")\n\n    # Objective\n    prob += Cmax\n\n    # Precedence constraints within each job\n    for j in jobs:\n        route = routes[j]\n        for k in range(len(route)-1):\n            oid_prev = f\"{j}_{k}\"\n            oid_next = f\"{j}_{k+1}\"\n            p_prev = next(o[\"p\"] for o in ops if o[\"job\"]==j and o[\"op_idx\"]==k)\n            prob += S[oid_next] >= S[oid_prev] + p_prev\n\n    # Machine non-overlap via disjunctive binaries\n    BIGM = H + sum(o[\"p\"] for o in ops)\n    for m in machines:\n        # operations on machine m\n        ops_m = [o for o in ops if o[\"machine\"]==m]\n        for i in range(len(ops_m)):\n            for k in range(i+1, len(ops_m)):\n                oi = ops_m[i]; ok = ops_m[k]\n                oi_id = f\"{oi['job']}_{oi['op_idx']}\"\n                ok_id = f\"{ok['job']}_{ok['op_idx']}\"\n                y = pulp.LpVariable(f\"y_{oi_id}_before_{ok_id}\", lowBound=0, upBound=1, cat=\"Binary\")\n                # If y=1 then oi before ok; else ok before oi\n                prob += S[ok_id] >= S[oi_id] + oi[\"p\"] - BIGM*(1-y)\n                prob += S[oi_id] >= S[ok_id] + ok[\"p\"] - BIGM*(y)\n\n    # Makespan constraints\n    for o in ops:\n        oid = f\"{o['job']}_{o['op_idx']}\"\n        prob += Cmax >= S[oid] + o[\"p\"]\n\n    # Solve\n    _ = prob.solve(pulp.PULP_CBC_CMD(msg=False))\n    status = pulp.LpStatus[prob.status]\n    if status not in (\"Optimal\", \"Feasible\"):\n        return status, None, None\n\n    S_sol = {oid: pulp.value(S[oid]) for oid in op_ids}\n    Cmax_sol = pulp.value(Cmax)\n    return status, S_sol, Cmax_sol\n\ndef heuristic_schedule(ops, jobs, machines):\n    # Simple list scheduling: each job follows its route; pick next schedulable op with earliest machine availability.\n    # Track availability times for machines and jobs.\n    m_avail = {m: 0 for m in machines}\n    j_avail = {j: 0 for j in jobs}\n    # Next operation index to schedule per job\n    next_k = {j: 0 for j in jobs}\n\n    S_sol = {}\n    finished_ops = 0\n    total_ops = len(ops)\n\n    # Pre-index processing times by (job, op_idx)\n    p = {(o[\"job\"], o[\"op_idx\"]): o[\"p\"] for o in ops}\n    m_of = {(o[\"job\"], o[\"op_idx\"]): o[\"machine\"] for o in ops}\n\n    while finished_ops < total_ops:\n        # Candidate ops ready to schedule: next per job if any remain\n        candidates = []\n        for j in jobs:\n            k = next_k[j]\n            if k < len(routes[j]):\n                m = m_of[(j,k)]\n                start_time = max(j_avail[j], m_avail[m])\n                candidates.append((start_time, j, k, m))\n        if not candidates:\n            break\n        # Choose the one with earliest possible start; tie-break by shortest proc time\n        candidates.sort(key=lambda t: (t[0], p[(t[1],t[2])]))\n        start, j, k, m = candidates[0]\n        oid = f\"{j}_{k}\"\n        S_sol[oid] = start\n        finish = start + p[(j,k)]\n        # Update availability\n        j_avail[j] = finish\n        m_avail[m] = finish\n        next_k[j] += 1\n        finished_ops += 1\n\n    Cmax = max(S_sol[oid] + next(o[\"p\"] for o in ops if f\"{o['job']}_{o['op_idx']}\"==oid) for oid in S_sol)\n    return \"Heuristic\", S_sol, Cmax\n\nif HAVE_PULP:\n    mip_status, S_mip, Cmax_mip = solve_mip_jobshop(ops, jobs, machines, H)\nelse:\n    mip_status, S_mip, Cmax_mip = heuristic_schedule(ops, jobs, machines)\n\nprint(\"MIP/Heuristic status:\", mip_status)\nprint(\"Cmax (MIP/Heuristic):\", Cmax_mip)\n"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "\n# Simple Gantt chart for the MIP/heuristic schedule\nimport matplotlib.pyplot as plt\n\nfig = plt.figure()\ny_ticks = []\ny_labels = []\ny = 0\nfor j in jobs:\n    # draw each job's ops as horizontal bars at level y\n    for k, m in enumerate(routes[j]):\n        oid = f\"{j}_{k}\"\n        s = S_mip[oid]\n        p = proc_times[j][m]\n        plt.barh(y, p, left=s)\n        plt.text(s + p/2, y, f\"{m}\", ha=\"center\", va=\"center\")\n    y_ticks.append(y)\n    y_labels.append(j)\n    y += 1\n\nplt.yticks(y_ticks, y_labels)\nplt.xlabel(\"Time\")\nplt.title(\"Gantt Chart \u2014 JSSP Schedule (MIP/Heuristic)\")\nplt.tight_layout()\n"}, {"cell_type": "markdown", "metadata": {}, "source": "\n## Part 2 \u2014 QUBO (Time-Indexed) on the Same Dataset\n\nWe define one-hot binary variables \\(x_{(j,k),t}\\) that equal 1 iff operation \\((j,k)\\) **starts** at time \\(t\\).  \nLet \\(p_{(j,k)}\\) be its processing time and \\(m_{(j,k)}\\) its machine.\n\n**Penalties:**\n1. **Start once:** \\(\\forall (j,k): \\big(1 - \\sum_t x_{(j,k),t}\\big)^2\\)  \n2. **Machine capacity:** \\(\\forall m, \\forall \\tau:\\; \\big(\\sum_{(j,k): m_{(j,k)}=m} \\sum_{t: \\tau\\in[t, t+p_{(j,k)}-1]} x_{(j,k),t} - 1\\big)^2\\)  \n3. **Precedence:** for consecutive ops \\((j,k)\\to(j,k+1)\\), forbid starts where \\(t_{k+1} < t_k + p_k\\) via pairwise penalties \\(x_{(j,k),t} \\cdot x_{(j,k+1),t'}\\) when \\(t' < t + p_k\\).\n\n**Objective:** Minimize makespan proxy by encouraging earlier starts: add a small linear bias \\(\\alpha \\sum_{(j,k),t} t \\cdot x_{(j,k),t}\\).  \n(Alternatively, include an explicit time-indexed completion penalty relative to a target horizon.)\n"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "\nfrom collections import defaultdict\nimport numpy as np, dimod, neal\n\n# Build op metadata\nop_list = []\nfor j in jobs:\n    for k, m in enumerate(routes[j]):\n        op_list.append((j, k, m, int(proc_times[j][m])))\n\n# Restrict feasible start times to keep model compact: [0, H - p]\nstart_domain = {}\nfor (j,k,m,p) in op_list:\n    start_domain[(j,k)] = list(range(0, max(1, H - p + 1)))\n\n# Penalty weights\nA = 5.0   # start-once\nB = 5.0   # machine capacity\nC = 5.0   # precedence\nalpha = 0.05  # small bias to prefer earlier starts\n\ndef var_key(j,k,t):  # label helper\n    return f\"x|{j}|{k}|{t}\"\n\nQ = defaultdict(float)\n\n# (1) Start-once penalties\nfor (j,k,m,p) in op_list:\n    dom = start_domain[(j,k)]\n    # (1 - sum_t x)^2 = 1 - 2 sum x + sum x + 2 sum_{t<u} x_t x_u\n    for t in dom:\n        Q[(var_key(j,k,t), var_key(j,k,t))] += (-A)  # -A after expansion\n    # pairwise within the op (t<u): +2A\n    for idx, t in enumerate(dom):\n        for u in dom[idx+1:]:\n            Q[(var_key(j,k,t), var_key(j,k,u))] += (2*A)\n\n# (2) Machine capacity: at each time tau, the number of running ops on machine m shouldn't exceed 1\n# O_{m,tau} = sum_{(j,k): m_{jk}=m} sum_{t in dom: tau in [t, t+p-1]} x_{jkt}\n# penalty: (O_{m,tau}-1)^2\nfor m in machines:\n    # gather op indices on m\n    ops_m = [(j,k,p) for (j,k,mm,p) in op_list if mm==m]\n    for tau in range(H):\n        # collect all (j,k,t) that run at tau\n        run_vars = []\n        for (j,k,p) in ops_m:\n            for t in start_domain[(j,k)]:\n                if (t <= tau) and (tau < t + p):\n                    run_vars.append((j,k,t))\n        # add terms: -2B sum x + B sum x  + 2B sum_{pairs} x x  => net linear (-B), pairwise (2B)\n        for (j,k,t) in run_vars:\n            Q[(var_key(j,k,t), var_key(j,k,t))] += (-B)\n        for idx, a in enumerate(run_vars):\n            for b in run_vars[idx+1:]:\n                Q[(var_key(*a), var_key(*b))] += (2*B)\n\n# (3) Precedence: forbid t_next < t + p_prev using pairwise penalties +C * x_prev(t) x_next(t')\nfor j in jobs:\n    route = routes[j]\n    for k in range(len(route)-1):\n        p_prev = int(proc_times[j][route[k]])\n        for t_prev in start_domain[(j,k)]:\n            for t_next in start_domain[(j,k+1)]:\n                if t_next < t_prev + p_prev:\n                    Q[(var_key(j,k,t_prev), var_key(j,k+1,t_next))] += C\n\n# (4) Early-start bias: alpha * sum t * x  (linear, on-diagonal)\nfor (j,k,m,p) in op_list:\n    for t in start_domain[(j,k)]:\n        Q[(var_key(j,k,t), var_key(j,k,t))] += (alpha * t)\n\n# Build and solve\nbqm = dimod.BinaryQuadraticModel.from_qubo(dict(Q))\nsampler = neal.SimulatedAnnealingSampler()\nsampleset = sampler.sample(bqm, num_reads=2000)\nbest = sampleset.first\n\nx = best.sample  # var -> 0/1\n# Decode to start times: pick t with x=1 per op; if multiple, choose earliest\nS_qubo = {}\nfor (j,k,m,p) in op_list:\n    dom = start_domain[(j,k)]\n    chosen = [t for t in dom if x.get(var_key(j,k,t), 0)==1]\n    if chosen:\n        S_qubo[f\"{j}_{k}\"] = min(chosen)\n    else:\n        # fall back: assign None (unscheduled)\n        S_qubo[f\"{j}_{k}\"] = None\n\n# Compute Cmax if fully scheduled\ncomplete = all(S_qubo[f\"{j}_{k}\"] is not None for (j,k,m,p) in op_list)\nif complete:\n    Cmax_qubo = max(S_qubo[f\"{j}_{k}\"] + p for (j,k,m,p) in op_list)\nelse:\n    Cmax_qubo = None\n\nprint(\"QUBO energy:\", best.energy)\nprint(\"Cmax (QUBO):\", Cmax_qubo)\n"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "\n# Gantt chart for the QUBO schedule (if complete)\nimport matplotlib.pyplot as plt\n\nif all(S_qubo.get(f\"{j}_{k}\") is not None for (j,k,m,p) in op_list):\n    fig = plt.figure()\n    y_ticks = []\n    y_labels = []\n    y = 0\n    for j in jobs:\n        for k, m in enumerate(routes[j]):\n            oid = f\"{j}_{k}\"\n            s = S_qubo[oid]\n            p = proc_times[j][m]\n            plt.barh(y, p, left=s)\n            plt.text(s + p/2, y, f\"{m}\", ha=\"center\", va=\"center\")\n        y_ticks.append(y)\n        y_labels.append(j)\n        y += 1\n    plt.yticks(y_ticks, y_labels)\n    plt.xlabel(\"Time\")\n    plt.title(\"Gantt Chart \u2014 QUBO Schedule\")\n    plt.tight_layout()\nelse:\n    print(\"QUBO schedule incomplete; skipping Gantt.\")\n"}, {"cell_type": "markdown", "metadata": {}, "source": "\n### Comparing MIP vs QUBO\n- **MIP** is exact (given a solver) for this formulation and typically finds optimal or near-optimal schedules for small\u2013medium instances.  \n- **QUBO** uses a **time-indexed** encoding with penalties; it\u2019s flexible and maps to **quantum annealing / QAOA**.  \n- The QUBO includes a small **early-start bias** as a makespan proxy; you can increase/decrease it or add a target-horizon penalty for tighter control.\n- Differences in \\(C_{\\max}\\) are expected; QUBO trades strict optimality for a formulation compatible with quantum/hybrid solvers.\n"}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}